episode num: 0
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [5.36890278e-05]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [0.12702926]
Step:50 loss_critic:0.00013892318643440995 loss_actor:tensor([[-0.1271]], grad_fn=<MulBackward0>)
reward for step 100 is [-0.00129817]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [0.33768395]
Step:100 loss_critic:5.643908297057127e-06 loss_actor:tensor([[0.0421]], grad_fn=<MulBackward0>)
reward for step 150 is [-0.0015386]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [0.36611357]
Step:150 loss_critic:4.1690907477056543e-07 loss_actor:tensor([[0.0183]], grad_fn=<MulBackward0>)
reward for step 200 is [-0.00539149]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [-0.6728099]
Step:200 loss_critic:0.00011398229066767566 loss_actor:tensor([[0.0593]], grad_fn=<MulBackward0>)
reward for step 250 is [-0.00576395]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [-0.82075047]
Step:250 loss_critic:1.0784255919384468e-05 loss_actor:tensor([[0.0022]], grad_fn=<MulBackward0>)
reward for step 300 is [-0.0078437]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [-0.95214218]
Step:300 loss_critic:3.962439570057651e-08 loss_actor:tensor([[0.0079]], grad_fn=<MulBackward0>)
reward for step 350 is [-0.01507738]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [-0.93692631]
Step:350 loss_critic:8.505044769084513e-07 loss_actor:tensor([[0.0035]], grad_fn=<MulBackward0>)
C:\Users\sari\Desktop\DeepCover\models\A2C\train.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  s1 = torch.tensor(s1)
C:\Users\sari\Desktop\DeepCover\models\A2C\train.py:94: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss_critic = F.smooth_l1_loss(y_predicted, y_expected)
reward for step 400 is [-0.01605949]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [-0.87999129]
Step:400 loss_critic:2.6071465724694132e-05 loss_actor:tensor([[0.0091]], grad_fn=<MulBackward0>)
reward for step 450 is [-0.02623569]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [0.86572582]
Step:450 loss_critic:6.931985837383176e-06 loss_actor:tensor([[0.0233]], grad_fn=<MulBackward0>)
reward for step 500 is [-0.06676015]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [0.99456668]
Step:500 loss_critic:6.548102855806952e-06 loss_actor:tensor([[0.0385]], grad_fn=<MulBackward0>)
reward for step 550 is [-0.07220585]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [0.9919129]
Step:550 loss_critic:5.7553221550759325e-08 loss_actor:tensor([[0.0338]], grad_fn=<MulBackward0>)
reward for step 600 is [-0.0741299]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [0.98403567]
Step:600 loss_critic:6.578653362049154e-08 loss_actor:tensor([[0.0341]], grad_fn=<MulBackward0>)
reward for step 650 is [-0.06638166]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [0.96428591]
Step:650 loss_critic:4.2235406788944675e-06 loss_actor:tensor([[0.0342]], grad_fn=<MulBackward0>)
reward for step 700 is [-0.0430091]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [0.91863108]
Step:700 loss_critic:2.197395782244988e-05 loss_actor:tensor([[0.0405]], grad_fn=<MulBackward0>)
reward for step 750 is [-0.05524336]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [0.78596866]
Step:750 loss_critic:7.422203164455774e-06 loss_actor:tensor([[0.0375]], grad_fn=<MulBackward0>)
reward for step 800 is [-0.07344848]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [0.4777869]
Step:800 loss_critic:1.3744664128544847e-05 loss_actor:tensor([[0.0365]], grad_fn=<MulBackward0>)
reward for step 850 is [-0.04040125]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [-0.05961046]
Step:850 loss_critic:0.00010369473911649236 loss_actor:tensor([[0.0095]], grad_fn=<MulBackward0>)
reward for step 900 is [-0.01559037]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [-0.42924765]
Step:900 loss_critic:2.6245490809460356e-07 loss_actor:tensor([[0.0160]], grad_fn=<MulBackward0>)
reward for step 950 is [0.04058691]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [-0.53395224]
Step:950 loss_critic:0.00012877963374819233 loss_actor:tensor([[-0.0637]], grad_fn=<MulBackward0>)
reward for step 1000 is [0.07857655]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [-0.79374254]
Step:1000 loss_critic:4.4957833974536e-06 loss_actor:tensor([[-0.0743]], grad_fn=<MulBackward0>)
reward for step 1050 is [0.09930474]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [-0.93132198]
Step:1050 loss_critic:4.3214385507078927e-05 loss_actor:tensor([[-0.0904]], grad_fn=<MulBackward0>)
reward for step 1100 is [0.10782844]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [-0.97343677]
Step:1100 loss_critic:3.762031207402342e-06 loss_actor:tensor([[-0.1097]], grad_fn=<MulBackward0>)
reward for step 1150 is [0.11561489]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [-0.98804587]
Step:1150 loss_critic:2.7233962251133836e-08 loss_actor:tensor([[-0.1156]], grad_fn=<MulBackward0>)
reward for step 1200 is [0.11615402]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [-0.99085808]
Step:1200 loss_critic:4.216370535989215e-06 loss_actor:tensor([[-0.1144]], grad_fn=<MulBackward0>)
reward for step 1250 is [0.11589389]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [-0.99396098]
Step:1250 loss_critic:2.7080911201592527e-06 loss_actor:tensor([[-0.1155]], grad_fn=<MulBackward0>)
reward for step 1300 is [0.12236896]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [-0.9954626]
Step:1300 loss_critic:6.004558489891742e-07 loss_actor:tensor([[-0.1234]], grad_fn=<MulBackward0>)
reward for step 1350 is [0.14263466]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [-0.99653417]
Step:1350 loss_critic:2.226422909876403e-05 loss_actor:tensor([[-0.1383]], grad_fn=<MulBackward0>)
reward for step 1400 is [0.13397446]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [-0.99722826]
Step:1400 loss_critic:1.2348410408818418e-06 loss_actor:tensor([[-0.1346]], grad_fn=<MulBackward0>)
episode num: 1
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.00071867]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [0.99853188]
Step:50 loss_critic:4.157875537960789e-06 loss_actor:tensor([[0.0022]], grad_fn=<MulBackward0>)
reward for step 100 is [-0.0093007]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [0.99879795]
Step:100 loss_critic:3.7496440116605715e-06 loss_actor:tensor([[0.0071]], grad_fn=<MulBackward0>)
reward for step 150 is [-0.01014864]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [0.99896055]
Step:150 loss_critic:9.615599511549391e-06 loss_actor:tensor([[0.0084]], grad_fn=<MulBackward0>)
reward for step 200 is [-0.02548617]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [0.99911332]
Step:200 loss_critic:9.46460702218421e-05 loss_actor:tensor([[0.0359]], grad_fn=<MulBackward0>)
reward for step 250 is [-0.03364785]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [0.99924302]
Step:250 loss_critic:5.075662337280019e-06 loss_actor:tensor([[0.0504]], grad_fn=<MulBackward0>)
reward for step 300 is [-0.0102314]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [0.99934733]
Step:300 loss_critic:5.678204591922589e-05 loss_actor:tensor([[0.0174]], grad_fn=<MulBackward0>)
reward for step 350 is [0.02227956]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [0.99943274]
Step:350 loss_critic:5.956706895593511e-05 loss_actor:tensor([[-0.0145]], grad_fn=<MulBackward0>)
reward for step 400 is [0.02482629]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [0.99950331]
Step:400 loss_critic:2.5024163229396462e-08 loss_actor:tensor([[-0.0264]], grad_fn=<MulBackward0>)
reward for step 450 is [0.05151673]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [0.9995721]
Step:450 loss_critic:5.2545271855502166e-05 loss_actor:tensor([[-0.0466]], grad_fn=<MulBackward0>)
reward for step 500 is [0.21221811]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [-0.99944234]
Step:500 loss_critic:6.40979864621586e-05 loss_actor:tensor([[-0.2025]], grad_fn=<MulBackward0>)
reward for step 550 is [0.26405815]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [-0.99950069]
Step:550 loss_critic:2.4723811888020176e-05 loss_actor:tensor([[-0.2808]], grad_fn=<MulBackward0>)
reward for step 600 is [0.2949409]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [-0.999551]
Step:600 loss_critic:0.00039134975728760094 loss_actor:tensor([[-0.2676]], grad_fn=<MulBackward0>)
reward for step 650 is [0.42296154]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [-0.99959522]
Step:650 loss_critic:0.0002188910848790835 loss_actor:tensor([[-0.4439]], grad_fn=<MulBackward0>)
reward for step 700 is [0.48174081]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [-0.99963433]
Step:700 loss_critic:1.2291603872043672e-06 loss_actor:tensor([[-0.4867]], grad_fn=<MulBackward0>)
reward for step 750 is [0.4620701]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [-0.99966836]
Step:750 loss_critic:0.00013030507664852538 loss_actor:tensor([[-0.4747]], grad_fn=<MulBackward0>)
reward for step 800 is [0.44736179]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [-0.99969798]
Step:800 loss_critic:4.5173784972096183e-05 loss_actor:tensor([[-0.4393]], grad_fn=<MulBackward0>)
reward for step 850 is [0.46656459]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [-0.99972373]
Step:850 loss_critic:8.938322177750915e-06 loss_actor:tensor([[-0.4641]], grad_fn=<MulBackward0>)
reward for step 900 is [0.47769797]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [-0.99974614]
Step:900 loss_critic:4.5407200927250693e-07 loss_actor:tensor([[-0.4800]], grad_fn=<MulBackward0>)
reward for step 950 is [0.47598789]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [-0.99976575]
Step:950 loss_critic:1.8358081117586359e-07 loss_actor:tensor([[-0.4778]], grad_fn=<MulBackward0>)
reward for step 1000 is [0.46712837]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [-0.99978298]
Step:1000 loss_critic:2.052960210229919e-05 loss_actor:tensor([[-0.4630]], grad_fn=<MulBackward0>)
reward for step 1050 is [0.45677363]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [-0.99979818]
Step:1050 loss_critic:3.308947094832929e-05 loss_actor:tensor([[-0.4528]], grad_fn=<MulBackward0>)
reward for step 1100 is [0.4381231]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [-0.99981165]
Step:1100 loss_critic:4.3892004315659266e-05 loss_actor:tensor([[-0.4449]], grad_fn=<MulBackward0>)
reward for step 1150 is [0.39760918]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [-0.99982357]
Step:1150 loss_critic:4.930266259201212e-06 loss_actor:tensor([[-0.3981]], grad_fn=<MulBackward0>)
reward for step 1200 is [0.40352271]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [-0.99983424]
Step:1200 loss_critic:1.2947860977428498e-05 loss_actor:tensor([[-0.4061]], grad_fn=<MulBackward0>)
reward for step 1250 is [0.40572444]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [-0.9998439]
Step:1250 loss_critic:1.689694776601577e-05 loss_actor:tensor([[-0.4022]], grad_fn=<MulBackward0>)
reward for step 1300 is [0.42059242]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [-0.99985254]
Step:1300 loss_critic:2.383215918910219e-05 loss_actor:tensor([[-0.4207]], grad_fn=<MulBackward0>)
reward for step 1350 is [0.46576853]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [-0.99986035]
Step:1350 loss_critic:1.7365530800866473e-07 loss_actor:tensor([[-0.4675]], grad_fn=<MulBackward0>)
reward for step 1400 is [0.44810272]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [-0.99986738]
Step:1400 loss_critic:2.114060312150007e-05 loss_actor:tensor([[-0.4460]], grad_fn=<MulBackward0>)
episode num: 2
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.00071975]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [0.99991435]
Step:50 loss_critic:4.663715153018883e-05 loss_actor:tensor([[0.0041]], grad_fn=<MulBackward0>)
reward for step 100 is [-0.00931372]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [0.99991685]
Step:100 loss_critic:8.63002900848068e-06 loss_actor:tensor([[0.0038]], grad_fn=<MulBackward0>)
reward for step 150 is [-0.01016265]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [0.9999184]
Step:150 loss_critic:4.5164900311440556e-06 loss_actor:tensor([[0.0073]], grad_fn=<MulBackward0>)
reward for step 200 is [-0.02551923]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [0.99991894]
Step:200 loss_critic:4.844736040203622e-06 loss_actor:tensor([[0.0287]], grad_fn=<MulBackward0>)
reward for step 250 is [-0.03369021]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [0.99991763]
Step:250 loss_critic:0.00014122995743596613 loss_actor:tensor([[0.0214]], grad_fn=<MulBackward0>)
reward for step 300 is [-0.01024904]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [0.99991417]
Step:300 loss_critic:1.1817662655873815e-05 loss_actor:tensor([[-0.0009]], grad_fn=<MulBackward0>)
reward for step 350 is [0.02229392]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [0.99990785]
Step:350 loss_critic:1.4122674247327207e-05 loss_actor:tensor([[-0.0227]], grad_fn=<MulBackward0>)
reward for step 400 is [0.02484259]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [0.99988288]
Step:400 loss_critic:9.982783482465952e-06 loss_actor:tensor([[-0.0579]], grad_fn=<MulBackward0>)
reward for step 450 is [0.0515561]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [0.99955183]
Step:450 loss_critic:8.934493937277449e-07 loss_actor:tensor([[-0.0615]], grad_fn=<MulBackward0>)
reward for step 500 is [0.21121902]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [-0.99758428]
Step:500 loss_critic:1.6178911334948485e-05 loss_actor:tensor([[-0.1960]], grad_fn=<MulBackward0>)
reward for step 550 is [0.26266078]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [-0.99131662]
Step:550 loss_critic:2.402402057811093e-05 loss_actor:tensor([[-0.2442]], grad_fn=<MulBackward0>)
reward for step 600 is [0.29330804]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [-0.97091562]
Step:600 loss_critic:0.0005395732691580444 loss_actor:tensor([[-0.2383]], grad_fn=<MulBackward0>)
reward for step 650 is [0.42053919]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [-0.91028106]
Step:650 loss_critic:2.0453751820124322e-06 loss_actor:tensor([[-0.3913]], grad_fn=<MulBackward0>)
reward for step 700 is [0.48060375]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [-0.75281155]
Step:700 loss_critic:5.069608049712227e-05 loss_actor:tensor([[-0.4554]], grad_fn=<MulBackward0>)
reward for step 750 is [0.45927532]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [-0.42778584]
Step:750 loss_critic:7.519451001910366e-06 loss_actor:tensor([[-0.4475]], grad_fn=<MulBackward0>)
reward for step 800 is [0.43916442]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [0.03905299]
Step:800 loss_critic:2.8418023227240096e-05 loss_actor:tensor([[-0.4306]], grad_fn=<MulBackward0>)
reward for step 850 is [0.47319642]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [0.47054884]
Step:850 loss_critic:1.3912425604932021e-05 loss_actor:tensor([[-0.4787]], grad_fn=<MulBackward0>)
reward for step 900 is [0.49721582]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [0.74393082]
Step:900 loss_critic:6.485613395291933e-05 loss_actor:tensor([[-0.4834]], grad_fn=<MulBackward0>)
reward for step 950 is [0.58122281]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [0.88220519]
Step:950 loss_critic:9.234358007659863e-05 loss_actor:tensor([[-0.5925]], grad_fn=<MulBackward0>)
reward for step 1000 is [0.65030668]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [0.94587839]
Step:1000 loss_critic:0.00020971055691473587 loss_actor:tensor([[-0.6570]], grad_fn=<MulBackward0>)
reward for step 1050 is [0.69688839]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [0.97460294]
Step:1050 loss_critic:0.000880203526302358 loss_actor:tensor([[-0.6426]], grad_fn=<MulBackward0>)
reward for step 1100 is [0.74537934]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [0.98772305]
Step:1100 loss_critic:2.47577045681853e-06 loss_actor:tensor([[-0.7556]], grad_fn=<MulBackward0>)
reward for step 1150 is [0.83850488]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [0.9938705]
Step:1150 loss_critic:1.675092678151213e-06 loss_actor:tensor([[-0.8420]], grad_fn=<MulBackward0>)
reward for step 1200 is [0.82721449]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [0.99683851]
Step:1200 loss_critic:6.890783184527277e-05 loss_actor:tensor([[-0.8485]], grad_fn=<MulBackward0>)
reward for step 1250 is [0.82272801]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [0.99831694]
Step:1250 loss_critic:2.710487051682388e-05 loss_actor:tensor([[-0.8349]], grad_fn=<MulBackward0>)
reward for step 1300 is [0.79921197]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [0.99907631]
Step:1300 loss_critic:7.185427127768549e-05 loss_actor:tensor([[-0.8045]], grad_fn=<MulBackward0>)
reward for step 1350 is [0.72769189]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [0.99947804]
Step:1350 loss_critic:0.00039903390311475515 loss_actor:tensor([[-0.7541]], grad_fn=<MulBackward0>)
reward for step 1400 is [0.75536184]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [0.99969679]
Step:1400 loss_critic:4.70403754398973e-05 loss_actor:tensor([[-0.7651]], grad_fn=<MulBackward0>)
episode num: 3
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.00097363]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [-0.99986452]
Step:50 loss_critic:2.807735897980135e-05 loss_actor:tensor([[0.0062]], grad_fn=<MulBackward0>)
reward for step 100 is [0.01167169]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [-0.99991792]
Step:100 loss_critic:3.270680869384612e-05 loss_actor:tensor([[-0.0154]], grad_fn=<MulBackward0>)
reward for step 150 is [0.01300319]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [-0.9999491]
Step:150 loss_critic:3.349539475783859e-08 loss_actor:tensor([[-0.0145]], grad_fn=<MulBackward0>)
reward for step 200 is [0.02880075]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [-0.99996769]
Step:200 loss_critic:1.0727184596223906e-05 loss_actor:tensor([[-0.0240]], grad_fn=<MulBackward0>)
reward for step 250 is [0.03741853]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [-0.99997902]
Step:250 loss_critic:0.00029558023972908103 loss_actor:tensor([[-0.0023]], grad_fn=<MulBackward0>)
reward for step 300 is [0.01387951]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [-0.99998611]
Step:300 loss_critic:1.0916008725477286e-06 loss_actor:tensor([[-0.0193]], grad_fn=<MulBackward0>)
reward for step 350 is [-0.01893294]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [-0.99999058]
Step:350 loss_critic:1.1676883870182514e-06 loss_actor:tensor([[0.0202]], grad_fn=<MulBackward0>)
reward for step 400 is [-0.02112533]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [-0.9999935]
Step:400 loss_critic:2.983051710151992e-05 loss_actor:tensor([[0.0111]], grad_fn=<MulBackward0>)
reward for step 450 is [-0.04762703]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [-0.99999541]
Step:450 loss_critic:0.00011389682023957636 loss_actor:tensor([[0.0574]], grad_fn=<MulBackward0>)
reward for step 500 is [-0.20526971]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [0.99999559]
Step:500 loss_critic:5.904711997455398e-09 loss_actor:tensor([[0.1966]], grad_fn=<MulBackward0>)
reward for step 550 is [-0.25537347]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [0.99999678]
Step:550 loss_critic:2.4952019119667417e-06 loss_actor:tensor([[0.2491]], grad_fn=<MulBackward0>)
reward for step 600 is [-0.28499158]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [0.99999762]
Step:600 loss_critic:0.0005864698047833233 loss_actor:tensor([[0.2696]], grad_fn=<MulBackward0>)
reward for step 650 is [-0.40794845]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [0.99999821]
Step:650 loss_critic:6.030789838067119e-05 loss_actor:tensor([[0.4056]], grad_fn=<MulBackward0>)
reward for step 700 is [-0.46342772]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [0.99999863]
Step:700 loss_critic:4.172333235711537e-05 loss_actor:tensor([[0.4544]], grad_fn=<MulBackward0>)
reward for step 750 is [-0.44462782]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [0.99999893]
Step:750 loss_critic:3.3460947405650214e-06 loss_actor:tensor([[0.4401]], grad_fn=<MulBackward0>)
reward for step 800 is [-0.43081997]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [0.99999917]
Step:800 loss_critic:1.0355669469268806e-05 loss_actor:tensor([[0.4311]], grad_fn=<MulBackward0>)
reward for step 850 is [-0.44774907]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [0.99999934]
Step:850 loss_critic:1.5839672177245335e-06 loss_actor:tensor([[0.4510]], grad_fn=<MulBackward0>)
reward for step 900 is [-0.45707793]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [0.99999946]
Step:900 loss_critic:2.1599074415377597e-06 loss_actor:tensor([[0.4591]], grad_fn=<MulBackward0>)
reward for step 950 is [-0.4518975]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [0.99999958]
Step:950 loss_critic:1.1834785272482227e-07 loss_actor:tensor([[0.4523]], grad_fn=<MulBackward0>)
reward for step 1000 is [-0.44044694]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [0.99999964]
Step:1000 loss_critic:3.605973197641756e-06 loss_actor:tensor([[0.4435]], grad_fn=<MulBackward0>)
reward for step 1050 is [-0.42784966]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [0.9999997]
Step:1050 loss_critic:4.936559844641048e-05 loss_actor:tensor([[0.4380]], grad_fn=<MulBackward0>)
reward for step 1100 is [-0.40800676]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [0.99999976]
Step:1100 loss_critic:3.1208955076053384e-06 loss_actor:tensor([[0.4038]], grad_fn=<MulBackward0>)
reward for step 1150 is [-0.36526852]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [0.99999976]
Step:1150 loss_critic:2.092519564716488e-06 loss_actor:tensor([[0.3676]], grad_fn=<MulBackward0>)
reward for step 1200 is [-0.37098038]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [0.99999982]
Step:1200 loss_critic:0.0001814203653590944 loss_actor:tensor([[0.3545]], grad_fn=<MulBackward0>)
reward for step 1250 is [-0.37291016]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [0.99999982]
Step:1250 loss_critic:9.914044839625697e-07 loss_actor:tensor([[0.3674]], grad_fn=<MulBackward0>)
reward for step 1300 is [-0.38777305]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [0.99999988]
Step:1300 loss_critic:2.9980151850351e-05 loss_actor:tensor([[0.4008]], grad_fn=<MulBackward0>)
reward for step 1350 is [-0.43361274]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [0.99999988]
Step:1350 loss_critic:0.00014923561091654874 loss_actor:tensor([[0.4285]], grad_fn=<MulBackward0>)
reward for step 1400 is [-0.41522111]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [0.99999988]
Step:1400 loss_critic:2.8187051829996373e-05 loss_actor:tensor([[0.4245]], grad_fn=<MulBackward0>)
episode num: 4
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.00077795]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [-0.9999997]
Step:50 loss_critic:1.661390447676691e-06 loss_actor:tensor([[-0.0113]], grad_fn=<MulBackward0>)
reward for step 100 is [0.00096649]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [0.99998468]
Step:100 loss_critic:1.0063349341706585e-09 loss_actor:tensor([[0.0026]], grad_fn=<MulBackward0>)
reward for step 150 is [0.00174531]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [-0.99999988]
Step:150 loss_critic:1.4151873860748664e-07 loss_actor:tensor([[-0.0006]], grad_fn=<MulBackward0>)
reward for step 200 is [0.00489922]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [-0.99999988]
Step:200 loss_critic:3.0018564239188224e-06 loss_actor:tensor([[-0.0097]], grad_fn=<MulBackward0>)
reward for step 250 is [0.00860791]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [-0.99995846]
Step:250 loss_critic:9.449699399176253e-05 loss_actor:tensor([[-9.6977e-05]], grad_fn=<MulBackward0>)
reward for step 300 is [-0.00348817]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [0.44448715]
Step:300 loss_critic:2.0271005514738212e-05 loss_actor:tensor([[0.0107]], grad_fn=<MulBackward0>)
reward for step 350 is [-0.01903494]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [0.99925971]
Step:350 loss_critic:2.236437270346475e-07 loss_actor:tensor([[0.0205]], grad_fn=<MulBackward0>)
reward for step 400 is [-0.01870069]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [0.99986953]
Step:400 loss_critic:2.8914674256461892e-06 loss_actor:tensor([[0.0212]], grad_fn=<MulBackward0>)
reward for step 450 is [-0.02233222]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [-0.99984366]
Step:450 loss_critic:1.059188168213345e-07 loss_actor:tensor([[0.0229]], grad_fn=<MulBackward0>)
reward for step 500 is [-0.04629039]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [-0.99996793]
Step:500 loss_critic:4.7468952497346345e-06 loss_actor:tensor([[0.0485]], grad_fn=<MulBackward0>)
reward for step 550 is [-0.06495265]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [-0.99997276]
Step:550 loss_critic:2.863979901326808e-05 loss_actor:tensor([[0.0773]], grad_fn=<MulBackward0>)
reward for step 600 is [-0.07781281]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [-0.99997288]
Step:600 loss_critic:0.000246833381715785 loss_actor:tensor([[0.1042]], grad_fn=<MulBackward0>)
reward for step 650 is [-0.15657546]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [-0.99996674]
Step:650 loss_critic:0.00024904808447408265 loss_actor:tensor([[0.1636]], grad_fn=<MulBackward0>)
reward for step 700 is [-0.22363341]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [-0.99993938]
Step:700 loss_critic:0.000249051392863352 loss_actor:tensor([[0.2110]], grad_fn=<MulBackward0>)
reward for step 750 is [-0.19322556]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [-0.99978137]
Step:750 loss_critic:2.954963728960528e-06 loss_actor:tensor([[0.1739]], grad_fn=<MulBackward0>)
reward for step 800 is [-0.15409767]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [-0.99879992]
Step:800 loss_critic:0.00013463632271322308 loss_actor:tensor([[0.1726]], grad_fn=<MulBackward0>)
reward for step 850 is [-0.22475212]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [-0.99324059]
Step:850 loss_critic:0.000753092625760707 loss_actor:tensor([[0.2544]], grad_fn=<MulBackward0>)
reward for step 900 is [-0.27699988]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [-0.97356397]
Step:900 loss_critic:2.300517944562346e-06 loss_actor:tensor([[0.2898]], grad_fn=<MulBackward0>)
reward for step 950 is [-0.44519565]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [-0.93418872]
Step:950 loss_critic:0.0012116203412696972 loss_actor:tensor([[0.4908]], grad_fn=<MulBackward0>)
reward for step 1000 is [-0.57743043]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [-0.8802157]
Step:1000 loss_critic:0.0002601272570992286 loss_actor:tensor([[0.5463]], grad_fn=<MulBackward0>)
reward for step 1050 is [-0.66116802]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [-0.83506292]
Step:1050 loss_critic:0.0006893742957263955 loss_actor:tensor([[0.6579]], grad_fn=<MulBackward0>)
reward for step 1100 is [-0.74076768]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [-0.88150877]
Step:1100 loss_critic:0.00015434962255896398 loss_actor:tensor([[0.7240]], grad_fn=<MulBackward0>)
reward for step 1150 is [-0.887688]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [-0.92169499]
Step:1150 loss_critic:0.00021543150136280748 loss_actor:tensor([[0.9099]], grad_fn=<MulBackward0>)
reward for step 1200 is [-0.87008938]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [-0.94933879]
Step:1200 loss_critic:1.4220561436377343e-05 loss_actor:tensor([[0.8689]], grad_fn=<MulBackward0>)
reward for step 1250 is [-0.86252534]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [-0.96735096]
Step:1250 loss_critic:2.368453940128398e-05 loss_actor:tensor([[0.8739]], grad_fn=<MulBackward0>)
reward for step 1300 is [-0.82973264]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [-0.97882998]
Step:1300 loss_critic:0.0007769268374370724 loss_actor:tensor([[0.8630]], grad_fn=<MulBackward0>)
reward for step 1350 is [-0.73135883]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [-0.98611194]
Step:1350 loss_critic:0.0009835594522046391 loss_actor:tensor([[0.7730]], grad_fn=<MulBackward0>)
reward for step 1400 is [-0.76822793]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [-0.99075502]
Step:1400 loss_critic:6.138201465838936e-05 loss_actor:tensor([[0.7775]], grad_fn=<MulBackward0>)
episode num: 5
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.00096667]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [-0.9942084]
Step:50 loss_critic:0.0004707603903241798 loss_actor:tensor([[-0.0169]], grad_fn=<MulBackward0>)
reward for step 100 is [0.01160015]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [-0.9960025]
Step:100 loss_critic:5.713862533445405e-06 loss_actor:tensor([[-0.0065]], grad_fn=<MulBackward0>)
reward for step 150 is [0.01287457]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [-0.72624642]
Step:150 loss_critic:3.564819015009216e-06 loss_actor:tensor([[-0.0084]], grad_fn=<MulBackward0>)
reward for step 200 is [0.02630167]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [0.99484414]
Step:200 loss_critic:1.5081959210913431e-06 loss_actor:tensor([[-0.0171]], grad_fn=<MulBackward0>)
reward for step 250 is [0.0293188]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [0.99614769]
Step:250 loss_critic:1.4578185293857723e-05 loss_actor:tensor([[-0.0325]], grad_fn=<MulBackward0>)
reward for step 300 is [0.02681101]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [0.99708146]
Step:300 loss_critic:3.015188034570358e-09 loss_actor:tensor([[-0.0234]], grad_fn=<MulBackward0>)
reward for step 350 is [0.02892854]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [0.9977591]
Step:350 loss_critic:8.153740656886485e-08 loss_actor:tensor([[-0.0256]], grad_fn=<MulBackward0>)
reward for step 400 is [0.03007493]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [0.9982571]
Step:400 loss_critic:9.57642832392983e-07 loss_actor:tensor([[-0.0245]], grad_fn=<MulBackward0>)
reward for step 450 is [0.03771225]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [-0.99953598]
Step:450 loss_critic:7.495714840948356e-07 loss_actor:tensor([[-0.0372]], grad_fn=<MulBackward0>)
reward for step 500 is [0.06983944]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [-0.9996382]
Step:500 loss_critic:6.99437728731392e-08 loss_actor:tensor([[-0.0682]], grad_fn=<MulBackward0>)
reward for step 550 is [0.07255951]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [-0.99971455]
Step:550 loss_critic:2.1817176632803455e-07 loss_actor:tensor([[-0.0702]], grad_fn=<MulBackward0>)
reward for step 600 is [0.07296609]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [-0.99977219]
Step:600 loss_critic:2.7322716053152804e-06 loss_actor:tensor([[-0.0695]], grad_fn=<MulBackward0>)
reward for step 650 is [0.05692009]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [-0.99981618]
Step:650 loss_critic:1.0187765837898453e-06 loss_actor:tensor([[-0.0543]], grad_fn=<MulBackward0>)
reward for step 700 is [0.02802889]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [-0.99985009]
Step:700 loss_critic:6.857201846725875e-06 loss_actor:tensor([[-0.0270]], grad_fn=<MulBackward0>)
reward for step 750 is [0.04324788]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [-0.99987656]
Step:750 loss_critic:3.9349443116756564e-05 loss_actor:tensor([[-0.0485]], grad_fn=<MulBackward0>)
reward for step 800 is [0.06604823]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [-0.99989742]
Step:800 loss_critic:1.634871331893106e-05 loss_actor:tensor([[-0.0703]], grad_fn=<MulBackward0>)
reward for step 850 is [0.02263992]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [-0.99991393]
Step:850 loss_critic:4.421054134013563e-06 loss_actor:tensor([[-0.0117]], grad_fn=<MulBackward0>)
reward for step 900 is [-0.01037055]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [-0.99992722]
Step:900 loss_critic:2.0441116387818287e-05 loss_actor:tensor([[0.0159]], grad_fn=<MulBackward0>)
reward for step 950 is [-0.12852415]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [-0.99993789]
Step:950 loss_critic:0.0003122347915625043 loss_actor:tensor([[0.1399]], grad_fn=<MulBackward0>)
reward for step 1000 is [-0.22399143]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [-0.99994665]
Step:1000 loss_critic:0.0010758830270717955 loss_actor:tensor([[0.2534]], grad_fn=<MulBackward0>)
reward for step 1050 is [-0.28613241]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [-0.99995381]
Step:1050 loss_critic:2.243871487546644e-05 loss_actor:tensor([[0.2629]], grad_fn=<MulBackward0>)
reward for step 1100 is [-0.34882424]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [-0.99995971]
Step:1100 loss_critic:2.594051855061125e-07 loss_actor:tensor([[0.3608]], grad_fn=<MulBackward0>)
reward for step 1150 is [-0.46698544]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [-0.99996459]
Step:1150 loss_critic:1.6220161468422205e-06 loss_actor:tensor([[0.4666]], grad_fn=<MulBackward0>)
reward for step 1200 is [-0.45246417]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [-0.99996877]
Step:1200 loss_critic:0.000620193310976607 loss_actor:tensor([[0.4977]], grad_fn=<MulBackward0>)
reward for step 1250 is [-0.44631728]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [-0.99997222]
Step:1250 loss_critic:7.853188512027524e-06 loss_actor:tensor([[0.4573]], grad_fn=<MulBackward0>)
reward for step 1300 is [-0.41807068]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [-0.99997514]
Step:1300 loss_critic:7.900110667741143e-06 loss_actor:tensor([[0.4109]], grad_fn=<MulBackward0>)
reward for step 1350 is [-0.333189]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [-0.99997771]
Step:1350 loss_critic:9.053354725212327e-07 loss_actor:tensor([[0.3309]], grad_fn=<MulBackward0>)
reward for step 1400 is [-0.36520206]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [-0.99997985]
Step:1400 loss_critic:1.2891019241827961e-06 loss_actor:tensor([[0.3753]], grad_fn=<MulBackward0>)
episode num: 6
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.0009738]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [-0.999982]
Step:50 loss_critic:3.0197196590740254e-05 loss_actor:tensor([[0.0220]], grad_fn=<MulBackward0>)
reward for step 100 is [0.01167326]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [-0.99998361]
Step:100 loss_critic:4.079180686480759e-06 loss_actor:tensor([[-0.0066]], grad_fn=<MulBackward0>)
reward for step 150 is [0.01300485]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [-0.99998492]
Step:150 loss_critic:3.6865358896807217e-06 loss_actor:tensor([[-0.0108]], grad_fn=<MulBackward0>)
reward for step 200 is [0.02896128]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [0.99994189]
Step:200 loss_critic:3.190173455519546e-06 loss_actor:tensor([[-0.0207]], grad_fn=<MulBackward0>)
reward for step 250 is [0.03315443]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [0.99994582]
Step:250 loss_critic:4.145680828428666e-05 loss_actor:tensor([[-0.0419]], grad_fn=<MulBackward0>)
reward for step 300 is [0.02793928]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [0.99994928]
Step:300 loss_critic:5.334631411713416e-07 loss_actor:tensor([[-0.0252]], grad_fn=<MulBackward0>)
reward for step 350 is [0.02689979]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [0.99995232]
Step:350 loss_critic:1.1498063048108762e-08 loss_actor:tensor([[-0.0254]], grad_fn=<MulBackward0>)
reward for step 400 is [0.02790301]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [0.99995506]
Step:400 loss_critic:6.436831515401612e-07 loss_actor:tensor([[-0.0248]], grad_fn=<MulBackward0>)
reward for step 450 is [0.03335958]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [-0.99999022]
Step:450 loss_critic:4.103227305726106e-07 loss_actor:tensor([[-0.0336]], grad_fn=<MulBackward0>)
reward for step 500 is [0.04018263]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [-0.99999076]
Step:500 loss_critic:7.108054362639481e-08 loss_actor:tensor([[-0.0394]], grad_fn=<MulBackward0>)
reward for step 550 is [0.03325367]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [-0.99999124]
Step:550 loss_critic:2.6301530653737774e-08 loss_actor:tensor([[-0.0332]], grad_fn=<MulBackward0>)
reward for step 600 is [0.02767328]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [-0.99999171]
Step:600 loss_critic:3.285308331077929e-05 loss_actor:tensor([[-0.0227]], grad_fn=<MulBackward0>)
reward for step 650 is [-0.01667783]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [-0.99999213]
Step:650 loss_critic:2.8962066642205834e-06 loss_actor:tensor([[0.0174]], grad_fn=<MulBackward0>)
reward for step 700 is [-0.06279646]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [-0.99999249]
Step:700 loss_critic:1.1291356494064712e-05 loss_actor:tensor([[0.0591]], grad_fn=<MulBackward0>)
reward for step 750 is [-0.04072121]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [-0.99999285]
Step:750 loss_critic:4.333487134101702e-05 loss_actor:tensor([[0.0271]], grad_fn=<MulBackward0>)
reward for step 800 is [-0.01054944]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [-0.99999315]
Step:800 loss_critic:7.000888251560782e-05 loss_actor:tensor([[-0.0027]], grad_fn=<MulBackward0>)
reward for step 850 is [-0.06626273]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [-0.99999338]
Step:850 loss_critic:1.7764520096445497e-06 loss_actor:tensor([[0.0822]], grad_fn=<MulBackward0>)
reward for step 900 is [-0.10794895]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [-0.99999368]
Step:900 loss_critic:3.5753422628127774e-05 loss_actor:tensor([[0.1122]], grad_fn=<MulBackward0>)
reward for step 950 is [-0.24898863]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [-0.99999386]
Step:950 loss_critic:0.0008109901546128209 loss_actor:tensor([[0.2756]], grad_fn=<MulBackward0>)
reward for step 1000 is [-0.36147817]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [-0.9999941]
Step:1000 loss_critic:0.0003254179624205482 loss_actor:tensor([[0.3938]], grad_fn=<MulBackward0>)
reward for step 1050 is [-0.43379754]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [-0.99999428]
Step:1050 loss_critic:0.0014017981584413773 loss_actor:tensor([[0.3438]], grad_fn=<MulBackward0>)
reward for step 1100 is [-0.50514564]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [-0.99999446]
Step:1100 loss_critic:1.564626821911916e-05 loss_actor:tensor([[0.5242]], grad_fn=<MulBackward0>)
reward for step 1150 is [-0.63856836]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [-0.99999464]
Step:1150 loss_critic:3.4487406672287524e-05 loss_actor:tensor([[0.6233]], grad_fn=<MulBackward0>)
reward for step 1200 is [-0.62235523]
obs for step 1200 is [1.527347553, 0.34346654609999805, 0.3434435461000021, 0.34334432624099803]
action for step1200 if [-0.99999481]
Step:1200 loss_critic:7.055927093820224e-07 loss_actor:tensor([[0.6097]], grad_fn=<MulBackward0>)
reward for step 1250 is [-0.61543293]
obs for step 1250 is [1.772414859, 0.33943654609999785, 0.33934354609999956, 0.3392443262409984]
action for step1250 if [-0.99999493]
Step:1250 loss_critic:0.000154386044167856 loss_actor:tensor([[0.5897]], grad_fn=<MulBackward0>)
reward for step 1300 is [-0.58455677]
obs for step 1300 is [1.773628746, 0.33513654610000004, 0.3355435461000013, 0.33524432624099915]
action for step1300 if [-0.99999505]
Step:1300 loss_critic:2.900799756236557e-05 loss_actor:tensor([[0.5615]], grad_fn=<MulBackward0>)
reward for step 1350 is [-0.49187101]
obs for step 1350 is [2.281299158, 0.32581654610000044, 0.3250435460999995, 0.32474432624099736]
action for step1350 if [-0.99999517]
Step:1350 loss_critic:0.0004579139866208918 loss_actor:tensor([[0.5251]], grad_fn=<MulBackward0>)
reward for step 1400 is [-0.52670399]
obs for step 1400 is [2.10191296, 0.32853654609999977, 0.3287435461000001, 0.32854432624099844]
action for step1400 if [-0.99999529]
Step:1400 loss_critic:1.8312606784239675e-06 loss_actor:tensor([[0.5221]], grad_fn=<MulBackward0>)
episode num: 7
------------reset obs----------------:[-184000.0, 140.5891, 140.573, 140.65]
reward for step 50 is [0.00097381]
obs for step 50 is [-0.0552975305, 0.10582654609999906, 0.10494354610000016, 0.10614432624099948]
action for step50 if [-0.99999541]
Step:50 loss_critic:0.00024487545665369346 loss_actor:tensor([[-0.0340]], grad_fn=<MulBackward0>)
reward for step 100 is [0.01167342]
obs for step 100 is [-0.0108740418, 0.09683654609999906, 0.09614354610000078, 0.09634432624099816]
action for step100 if [-0.99999553]
Step:100 loss_critic:3.789328600147074e-06 loss_actor:tensor([[-0.0054]], grad_fn=<MulBackward0>)
reward for step 150 is [0.01300502]
obs for step 150 is [-0.2820937804, 0.09373654609999846, 0.09354354609999974, 0.09374432624099996]
action for step150 if [-0.99999559]
Step:150 loss_critic:3.6693953620056945e-06 loss_actor:tensor([[-0.0105]], grad_fn=<MulBackward0>)
reward for step 200 is [0.02913816]
obs for step 200 is [-2.730529788, 0.08093654609999987, 0.08114354610000021, 0.08094432624099852]
action for step200 if [0.99997962]
Step:200 loss_critic:3.2293238594851826e-06 loss_actor:tensor([[-0.0213]], grad_fn=<MulBackward0>)
reward for step 250 is [0.03386945]
obs for step 250 is [-2.21028657, 0.08011654609999823, 0.07994354610000017, 0.07974432624099848]
action for step250 if [0.99997991]
Step:250 loss_critic:2.6163105908621405e-05 loss_actor:tensor([[-0.0455]], grad_fn=<MulBackward0>)
reward for step 300 is [0.02740723]
obs for step 300 is [-2.719764947, 0.08723654609999869, 0.08744354610000186, 0.08724432624099734]
action for step300 if [0.99998015]
Step:300 loss_critic:9.380469375262817e-07 loss_actor:tensor([[-0.0239]], grad_fn=<MulBackward0>)
reward for step 350 is [0.02490646]
obs for step 350 is [-1.483896883, 0.09908654609999985, 0.0991435461000009, 0.0989443262409992]
action for step350 if [0.99998039]
Step:350 loss_critic:2.2607731483611649e-10 loss_actor:tensor([[-0.0230]], grad_fn=<MulBackward0>)
reward for step 400 is [0.02584246]
obs for step 400 is [-0.9297053586, 0.09863654609999913, 0.09944354609999947, 0.0992443262409978]
action for step400 if [0.99998057]
Step:400 loss_critic:4.151600672876114e-08 loss_actor:tensor([[-0.0229]], grad_fn=<MulBackward0>)
reward for step 450 is [0.03035129]
obs for step 450 is [0.0334292625, 0.10543654610000033, 0.10564354610000067, 0.1053443262409985]
action for step450 if [-0.99999601]
Step:450 loss_critic:7.628823924292389e-09 loss_actor:tensor([[-0.0286]], grad_fn=<MulBackward0>)
reward for step 500 is [0.03142097]
obs for step 500 is [3.009303128, 0.1402365460999988, 0.14084354610000105, 0.14084432624099746]
action for step500 if [-0.99999601]
Step:500 loss_critic:8.374353603890059e-10 loss_actor:tensor([[-0.0298]], grad_fn=<MulBackward0>)
reward for step 550 is [0.02229883]
obs for step 550 is [3.3740230889999996, 0.15781654609999976, 0.15804354610000076, 0.15794432624099955]
action for step550 if [-0.99999607]
Step:550 loss_critic:1.2628049762486168e-07 loss_actor:tensor([[-0.0215]], grad_fn=<MulBackward0>)
reward for step 600 is [0.0153577]
obs for step 600 is [2.812652163, 0.16117654610000046, 0.16124354610000183, 0.16114432624099778]
action for step600 if [-0.99999607]
Step:600 loss_critic:5.576931845370478e-05 loss_actor:tensor([[-0.0145]], grad_fn=<MulBackward0>)
reward for step 650 is [-0.03542579]
obs for step 650 is [2.6334528319999997, 0.20829654609999865, 0.20804354610000075, 0.2077443262409986]
action for step650 if [-0.99999613]
Step:650 loss_critic:3.171272378004007e-07 loss_actor:tensor([[0.0367]], grad_fn=<MulBackward0>)
reward for step 700 is [-0.08545868]
obs for step 700 is [3.550600937, 0.22561654609999948, 0.22624354609999955, 0.22604432624099785]
action for step700 if [-0.99999619]
Step:700 loss_critic:3.723910501670569e-05 loss_actor:tensor([[0.0931]], grad_fn=<MulBackward0>)
reward for step 750 is [-0.06182572]
obs for step 750 is [3.403482525, 0.2185665460999985, 0.2186435461000002, 0.21834432624099803]
action for step750 if [-0.99999619]
Step:750 loss_critic:0.00015514917404633584 loss_actor:tensor([[0.0618]], grad_fn=<MulBackward0>)
reward for step 800 is [-0.02997936]
obs for step 800 is [3.169628629, 0.2098665460999996, 0.20954354610000223, 0.2093443262409977]
action for step800 if [-0.99999624]
Step:800 loss_critic:0.000122103828360417 loss_actor:tensor([[0.0247]], grad_fn=<MulBackward0>)
reward for step 850 is [-0.08848793]
obs for step 850 is [3.4489956439999996, 0.22711654609999812, 0.22724354610000147, 0.22714432624099742]
action for step850 if [-0.99999624]
Step:850 loss_critic:2.6032925404615285e-06 loss_actor:tensor([[0.0890]], grad_fn=<MulBackward0>)
reward for step 900 is [-0.13214495]
obs for step 900 is [2.6511508569999997, 0.23861654609999902, 0.23834354610000047, 0.23754432624099878]
action for step900 if [-0.99999624]
Step:900 loss_critic:7.634678085232546e-05 loss_actor:tensor([[0.1324]], grad_fn=<MulBackward0>)
reward for step 950 is [-0.27838307]
obs for step 950 is [2.0139853569999997, 0.27273654609999765, 0.2733435460999999, 0.2732443262409987]
action for step950 if [-0.9999963]
Step:950 loss_critic:0.0006254755865891592 loss_actor:tensor([[0.3279]], grad_fn=<MulBackward0>)
reward for step 1000 is [-0.39473904]
obs for step 1000 is [1.804490167, 0.2961465460999989, 0.29464354610000215, 0.2945443262409981]
action for step1000 if [-0.9999963]
Step:1000 loss_critic:8.486979853420782e-05 loss_actor:tensor([[0.3945]], grad_fn=<MulBackward0>)
reward for step 1050 is [-0.46937028]
obs for step 1050 is [1.6248239759999998, 0.3048765460999988, 0.3051435461000011, 0.30484432624099894]
action for step1050 if [-0.99999636]
Step:1050 loss_critic:0.0014491546156864877 loss_actor:tensor([[0.4814]], grad_fn=<MulBackward0>)
reward for step 1100 is [-0.54268444]
obs for step 1100 is [1.5959631069999998, 0.32043654609999805, 0.32044354610000025, 0.3202443262409986]
action for step1100 if [-0.99999636]
Step:1100 loss_critic:0.00022140249691234476 loss_actor:tensor([[0.5439]], grad_fn=<MulBackward0>)
reward for step 1150 is [-0.67957341]
obs for step 1150 is [1.988132073, 0.34303654609999795, 0.34284354610000206, 0.3425443262409999]
action for step1150 if [-0.99999636]
Step:1150 loss_critic:4.528951427757806e-05 loss_actor:tensor([[0.6871]], grad_fn=<MulBackward0>)
Traceback (most recent call last):
  File "C:\Users\sari\Desktop\DeepCover\main.py", line 100, in <module>
    main()
  File "C:\Users\sari\Desktop\DeepCover\main.py", line 93, in main
    wandb.log({'Reward throughout epoch(PL)': reward})
  File "C:\Users\sari\AppData\Local\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 419, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\sari\AppData\Local\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 370, in wrapper_fn
    return func(self, *args, **kwargs)
  File "C:\Users\sari\AppData\Local\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 360, in wrapper
    return func(self, *args, **kwargs)
  File "C:\Users\sari\AppData\Local\anaconda3\lib\site-packages\wandb\sdk\wandb_run.py", line 1785, in log
    if sync is not None:
KeyboardInterrupt